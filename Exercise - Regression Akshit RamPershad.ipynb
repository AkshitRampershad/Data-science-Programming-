{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - Regression\n",
    "\n",
    "\n",
    "The data set for this exercise includes information on house sales in King County, WA (between May 2014 and May 2015). (Each row in the data set pertains to one house. There is a total of 21,613 houses in the data set). Use this data set to predict the sale price of a house (i.e., the `price` column) based on the characteristics of the house. A model can be helpful for buyers, sellers, realtors, and lenders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "The description and type of each variable is provided in \"KC house data - Data Dictionary.docx\". Make sure to read this document to learn about the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the **kc_house_data.csv** data set and build a model to predict **price**. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2060.0</td>\n",
       "      <td>329903.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2060</td>\n",
       "      <td>0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>0</td>\n",
       "      <td>zip_98022</td>\n",
       "      <td>47.1776</td>\n",
       "      <td>-121.944</td>\n",
       "      <td>2240</td>\n",
       "      <td>220232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>810.0</td>\n",
       "      <td>8424.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>810</td>\n",
       "      <td>0</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>0</td>\n",
       "      <td>zip_98023</td>\n",
       "      <td>47.3286</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>820</td>\n",
       "      <td>8424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>235000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>960.0</td>\n",
       "      <td>5030.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>0</td>\n",
       "      <td>zip_98118</td>\n",
       "      <td>47.5611</td>\n",
       "      <td>-122.280</td>\n",
       "      <td>1460</td>\n",
       "      <td>5400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>350000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>830.0</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>830</td>\n",
       "      <td>0</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>0</td>\n",
       "      <td>zip_98126</td>\n",
       "      <td>47.5259</td>\n",
       "      <td>-122.379</td>\n",
       "      <td>1220</td>\n",
       "      <td>5100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>397380</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>5072.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1030</td>\n",
       "      <td>0</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>1958</td>\n",
       "      <td>zip_98115</td>\n",
       "      <td>47.6962</td>\n",
       "      <td>-122.294</td>\n",
       "      <td>1220</td>\n",
       "      <td>6781.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
       "0  432000       5.0       2.75       2060.0  329903.0     1.5           0   \n",
       "1  170000       2.0       1.00        810.0    8424.0     1.0           0   \n",
       "2  235000       3.0       1.00        960.0    5030.0     1.0           0   \n",
       "3  350000       2.0       1.00        830.0    5100.0     1.0           0   \n",
       "4  397380       2.0       1.00       1030.0    5072.0     1.0           0   \n",
       "\n",
       "   view  condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
       "0     3          5    7.0        2060              0    1989.0             0   \n",
       "1     0          4    6.0         810              0    1959.0             0   \n",
       "2     0          3    7.0         960              0    1955.0             0   \n",
       "3     0          4    7.0         830              0    1942.0             0   \n",
       "4     0          3    6.0        1030              0    1924.0          1958   \n",
       "\n",
       "     zipcode      lat     long  sqft_living15  sqft_lot15  \n",
       "0  zip_98022  47.1776 -121.944           2240    220232.0  \n",
       "1  zip_98023  47.3286 -122.346            820      8424.0  \n",
       "2  zip_98118  47.5611 -122.280           1460      5400.0  \n",
       "3  zip_98126  47.5259 -122.379           1220      5100.0  \n",
       "4  zip_98115  47.6962 -122.294           1220      6781.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will predict the \"price\" value in the data set:\n",
    "\n",
    "housing = pd.read_csv(\"C:\\\\Users\\\\hp\\\\Desktop\\\\BAIS Semester2\\\\DSP\\\\Module2\\\\kc_house_data.csv\")\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(housing, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "Perform your data prep here. You can use pipelines like we do in the tutorials. Otherwise, feel free to use your own data prep steps. Eventually, you should do the following at a minimum:<br>\n",
    "- Separate inputs from target<br>\n",
    "- Impute/remove missing values<br>\n",
    "- Standardize the continuous variables<br>\n",
    "- One-hot encode categorical variables<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate the target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train['price']\n",
    "test_target = test['price']\n",
    "\n",
    "train_inputs = train.drop(['price'], axis=1)\n",
    "test_inputs = test.drop(['price'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the data type of \"zipcode\" to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs['zipcode'] = train_inputs['zipcode'].astype('object')\n",
    "test_inputs['zipcode'] = test_inputs['zipcode'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Identify the numeric, binary, and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bedrooms         float64\n",
       "bathrooms        float64\n",
       "sqft_living      float64\n",
       "sqft_lot         float64\n",
       "floors           float64\n",
       "waterfront         int64\n",
       "view               int64\n",
       "condition          int64\n",
       "grade            float64\n",
       "sqft_above         int64\n",
       "sqft_basement      int64\n",
       "yr_built         float64\n",
       "yr_renovated       int64\n",
       "zipcode           object\n",
       "lat              float64\n",
       "long             float64\n",
       "sqft_living15      int64\n",
       "sqft_lot15       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numerical columns\n",
    "numeric_columns = train_inputs.select_dtypes(include=[np.number]).columns.to_list()\n",
    "\n",
    "# Identify the categorical columns\n",
    "categorical_columns = train_inputs.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the binary columns so we can pass them through without transforming\n",
    "binary_columns = ['waterfront']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful: numerical columns already includes the binary columns,\n",
    "# So, we need to remove the binary columns from numerical columns.\n",
    "\n",
    "for col in binary_columns:\n",
    "    numeric_columns.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['waterfront']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bedrooms',\n",
       " 'bathrooms',\n",
       " 'sqft_living',\n",
       " 'sqft_lot',\n",
       " 'floors',\n",
       " 'view',\n",
       " 'condition',\n",
       " 'grade',\n",
       " 'sqft_above',\n",
       " 'sqft_basement',\n",
       " 'yr_built',\n",
       " 'yr_renovated',\n",
       " 'lat',\n",
       " 'long',\n",
       " 'sqft_living15',\n",
       " 'sqft_lot15']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zipcode']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns),\n",
    "        ('binary', binary_transformer, binary_columns)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "#passtrough is an optional step. You don't have to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns),\n",
    "        ('binary', binary_transformer, binary_columns)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "#passtrough is an optional step. You don't have to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform: fit_transform() for TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13724x87 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 233340 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit and transform the train data\n",
    "train_x = preprocessor.fit_transform(train_inputs)\n",
    "\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13724, 87)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranform: transform() for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5882x87 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 100008 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test data\n",
    "test_x = preprocessor.transform(test_inputs)\n",
    "\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5882, 87)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdummy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DummyRegressor\n\u001b[0;32m      3\u001b[0m dummy_regr \u001b[38;5;241m=\u001b[39m DummyRegressor(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m dummy_regr\u001b[38;5;241m.\u001b[39mfit(train_x, \u001b[43mtrain_y\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_y' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy_regr = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "dummy_regr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the baseline Train RMSE\n",
    "\n",
    "dummy_train_pred = dummy_regr.predict(train_x)\n",
    "\n",
    "baseline_train_mse = mean_squared_error(train_y, dummy_train_pred)\n",
    "\n",
    "baseline_train_rmse = np.sqrt(baseline_train_mse)\n",
    "\n",
    "print('Baseline Train RMSE: {}' .format(baseline_train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the baseline Test RMSE\n",
    "\n",
    "dummy_test_pred = dummy_regr.predict(test_x)\n",
    "\n",
    "baseline_test_mse = mean_squared_error (test_y, dummy_test_pred)\n",
    "\n",
    "baseline_test_rmse = np.sqrt(baseline_test_mse)\n",
    "\n",
    "print('Baseline Test RMSE: {}' .format(baseline_test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a SGD model (with no regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor \n",
    "\n",
    "# eta0 = learning rate\n",
    "# penalty = regularization term\n",
    "# max_iter = number of passes over training data (i.e., epochs)\n",
    "\n",
    "sgd_reg = SGDRegressor(max_iter=100, penalty=None, eta0=0.01) \n",
    "\n",
    "sgd_reg.fit(train_x, train_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicted vs. Actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame\n",
    "\n",
    "predictions = pd.DataFrame(sgd_reg.predict(test_x), columns=['Predicted'])\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the actual to the same DataFrame\n",
    "\n",
    "predictions['Actual'] = np.array(test_target)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = sgd_reg.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "\n",
    "reg_test_pred = sgd_reg.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try L1 Regularization in SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient:\n",
    "\n",
    "sgd_reg_L1 = SGDRegressor(max_iter=100, penalty='l1', alpha = 0.1, eta0=0.01)\n",
    "\n",
    "sgd_reg_L1.fit(train_x, train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = sgd_reg_L1.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = sgd_reg_L1.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# tol is the early stopping criteria\n",
    "\n",
    "sgd_reg_ES = SGDRegressor(max_iter=100, early_stopping = True, n_iter_no_change=5, tol=0.0001, \n",
    "                          validation_fraction=0.2, eta0=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg_L1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg_L1.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = sgd_reg_L1.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = sgd_reg_L1.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try L2 Regularization in SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sgd_reg_L2 = SGDRegressor(max_iter=100, penalty='l2', alpha = 20000, eta0=0.01)\n",
    "\n",
    "sgd_reg_L2.fit(train_x, train_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "\n",
    "reg_train_pred = sgd_reg_L2.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = sgd_reg_L2.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# tol is the early stopping criteria\n",
    "\n",
    "sgd_reg_ES = SGDRegressor(max_iter=90, early_stopping = True, n_iter_no_change=5, tol=0.0001, \n",
    "                          validation_fraction=0.2, eta0=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg_L2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg_L2.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = sgd_reg_L2.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = sgd_reg_L2.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try ElasticNet in SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient:\n",
    "\n",
    "sgd_reg_elastic = SGDRegressor(max_iter=90, penalty='elasticnet', l1_ratio=0.5, alpha = 10, \n",
    "                          eta0=0.01)\n",
    "sgd_reg_elastic.fit(train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = sgd_reg_elastic.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = sgd_reg_elastic.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Polynomial Features\n",
    "\n",
    "Create polynomial features with degree = 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create second degree terms and interaction terms\n",
    "poly_features = PolynomialFeatures(degree=2).fit(train_x)\n",
    "\n",
    "train_x_poly = poly_features.transform(train_x)\n",
    "\n",
    "test_x_poly = poly_features.transform(test_x)\n",
    "\n",
    "#This will create the polynomial terms of the categorical variables too\n",
    "\n",
    "#if degree=3, then it creates all combinations: a, a^2, a^3, b, b^2, b^3, a.b, a^2.b, a.b^2, a^2.b^2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We still fit a linear regression model\n",
    "\n",
    "pol_lin_reg = SGDRegressor(max_iter=1000, penalty=None, eta0=0.01) \n",
    "\n",
    "pol_lin_reg.fit(train_x_poly, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "reg_train_pred = pol_lin_reg.predict(train_x_poly)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, reg_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "reg_test_pred = pol_lin_reg.predict(test_x_poly)\n",
    "\n",
    "test_mse = mean_squared_error (test_y, reg_test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try L2 Regularization in SGD (with polynomial features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pol_lin_reg = SGDRegressor(max_iter=1000, penalty='l2',alpha = 0.1, eta0=0.01) \n",
    "\n",
    "pol_lin_reg.fit(train_x_poly, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg_pred_train =pol_lin_reg .predict(train_x_poly)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, poly_reg_pred_train)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg_pred_test =pol_lin_reg .predict(train_x_poly)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, poly_reg_pred_test)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
